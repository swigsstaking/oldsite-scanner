"""
Module pour r√©cup√©rer automatiquement les domaines .ch depuis crt.sh (Certificate Transparency logs)
"""

import asyncio
import aiohttp
import aiofiles
import re
import json
import os
from datetime import datetime
from typing import Set, List
import socket


# Configuration
YEARS = list(range(2020, 2026))  # 2020 √† 2025
OUTFILE = "domains_final.txt"
PROJECT_ROOT = os.path.dirname(os.path.dirname(__file__))
OUTPUT_PATH = os.path.join(PROJECT_ROOT, OUTFILE)
CRTSH_BASE_URL = "https://crt.sh/"


def clean_domain(raw_domain: str) -> str:
    """
    Nettoie un domaine extrait de crt.sh
    
    Args:
        raw_domain: Domaine brut (peut contenir *, protocoles, etc.)
    
    Returns:
        Domaine nettoy√© ou None si invalide
    """
    if not raw_domain:
        return None
    
    # Enlever les espaces
    domain = raw_domain.strip().lower()
    
    # Enlever les wildcards
    domain = domain.replace('*.', '')
    domain = domain.replace('*', '')
    
    # Enlever les protocoles
    domain = re.sub(r'^https?://', '', domain)
    domain = re.sub(r'^ftp://', '', domain)
    
    # Enlever les chemins
    domain = domain.split('/')[0]
    
    # Enlever les ports
    domain = domain.split(':')[0]
    
    # Enlever les espaces et caract√®res sp√©ciaux
    domain = domain.strip()
    
    # V√©rifier que c'est bien un .ch
    if not domain.endswith('.ch'):
        return None
    
    # V√©rifier qu'il n'y a pas de caract√®res bizarres
    if not re.match(r'^[a-z0-9.-]+\.ch$', domain):
        return None
    
    # Enlever les sous-domaines trop profonds (garder max 2 niveaux)
    parts = domain.split('.')
    if len(parts) > 3:  # ex: sub.sub.domain.ch -> trop profond
        return None
    
    return domain


async def fetch_crtsh_year(session: aiohttp.ClientSession, year: int) -> Set[str]:
    """
    R√©cup√®re les domaines .ch pour une ann√©e donn√©e depuis crt.sh
    
    Args:
        session: Session aiohttp
        year: Ann√©e √† interroger
    
    Returns:
        Set de domaines trouv√©s
    """
    domains = set()
    
    # Requ√™te pour l'ann√©e
    # Format: https://crt.sh/?q=%.ch&output=json&minNotBefore=2024-01-01&maxNotBefore=2024-12-31
    params = {
        'q': '%.ch',
        'output': 'json',
        'minNotBefore': f'{year}-01-01',
        'maxNotBefore': f'{year}-12-31'
    }
    
    print(f"üîç Interrogation crt.sh pour l'ann√©e {year}...")
    
    try:
        async with session.get(CRTSH_BASE_URL, params=params, timeout=aiohttp.ClientTimeout(total=120)) as response:
            if response.status != 200:
                print(f"   ‚ö†Ô∏è  Erreur HTTP {response.status} pour {year}")
                return domains
            
            text = await response.text()
            
            # Parser le JSON
            try:
                data = json.loads(text)
            except json.JSONDecodeError:
                print(f"   ‚ö†Ô∏è  Erreur de parsing JSON pour {year}")
                return domains
            
            if not isinstance(data, list):
                print(f"   ‚ö†Ô∏è  Format inattendu pour {year}")
                return domains
            
            # Extraire les domaines
            for entry in data:
                if not isinstance(entry, dict):
                    continue
                
                # Le champ peut √™tre 'name_value' ou 'common_name'
                raw_domains = entry.get('name_value', '') or entry.get('common_name', '')
                
                # Peut contenir plusieurs domaines s√©par√©s par \n
                for raw_domain in raw_domains.split('\n'):
                    cleaned = clean_domain(raw_domain)
                    if cleaned:
                        domains.add(cleaned)
            
            print(f"   ‚úÖ {year}: {len(domains)} domaines trouv√©s")
            
    except asyncio.TimeoutError:
        print(f"   ‚è±Ô∏è  Timeout pour {year}")
    except Exception as e:
        print(f"   ‚ùå Erreur pour {year}: {e}")
    
    return domains


async def verify_domain_dns(domain: str) -> bool:
    """
    V√©rifie qu'un domaine r√©sout en DNS (optionnel, peut √™tre lent)
    
    Args:
        domain: Domaine √† v√©rifier
    
    Returns:
        True si le domaine r√©sout
    """
    try:
        loop = asyncio.get_event_loop()
        await loop.getaddrinfo(domain, None)
        return True
    except:
        return False


async def fetch_all_domains(verify_dns: bool = False, progress_callback=None) -> Set[str]:
    """
    R√©cup√®re tous les domaines .ch depuis crt.sh
    
    Args:
        verify_dns: Si True, v√©rifie que les domaines r√©solvent (lent!)
        progress_callback: Fonction appel√©e avec le nombre de domaines trouv√©s
    
    Returns:
        Set de tous les domaines trouv√©s
    """
    all_domains = set()
    
    # Cr√©er une session HTTP
    timeout = aiohttp.ClientTimeout(total=120)
    connector = aiohttp.TCPConnector(limit=10)  # Max 10 connexions simultan√©es
    
    async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
        # Lancer les requ√™tes pour toutes les ann√©es en parall√®le
        tasks = [fetch_crtsh_year(session, year) for year in YEARS]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Combiner les r√©sultats
        for i, result in enumerate(results):
            if isinstance(result, set):
                all_domains.update(result)
                # Appeler le callback de progression
                if progress_callback:
                    await progress_callback(len(all_domains))
            elif isinstance(result, Exception):
                print(f"   ‚ö†Ô∏è  Une requ√™te a √©chou√©: {result}")
    
    print(f"\nüìä Total brut: {len(all_domains)} domaines uniques")
    
    # V√©rification DNS optionnelle
    if verify_dns and all_domains:
        print(f"\nüîç V√©rification DNS de {len(all_domains)} domaines (peut prendre du temps)...")
        verified = set()
        
        # V√©rifier par lots de 100
        domains_list = list(all_domains)
        batch_size = 100
        
        for i in range(0, len(domains_list), batch_size):
            batch = domains_list[i:i+batch_size]
            tasks = [verify_domain_dns(d) for d in batch]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for domain, result in zip(batch, results):
                if result is True:
                    verified.add(domain)
            
            print(f"   V√©rifi√© {min(i+batch_size, len(domains_list))}/{len(domains_list)} domaines...")
        
        print(f"   ‚úÖ {len(verified)} domaines r√©solvent en DNS")
        all_domains = verified
    
    return all_domains


async def save_domains(domains: Set[str], filepath: str):
    """
    Sauvegarde les domaines dans un fichier
    
    Args:
        domains: Set de domaines
        filepath: Chemin du fichier de sortie
    """
    # Trier les domaines
    sorted_domains = sorted(list(domains))
    
    print(f"\nüíæ Sauvegarde de {len(sorted_domains)} domaines dans {filepath}...")
    
    async with aiofiles.open(filepath, 'w') as f:
        # Header
        await f.write(f"# Liste de domaines .ch r√©cup√©r√©s depuis crt.sh\n")
        await f.write(f"# G√©n√©r√© le {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        await f.write(f"# Total: {len(sorted_domains)} domaines\n")
        await f.write(f"# Ann√©es: {min(YEARS)}-{max(YEARS)}\n")
        await f.write(f"#\n")
        await f.write(f"# Un domaine par ligne\n")
        await f.write(f"\n")
        
        # Domaines
        for domain in sorted_domains:
            await f.write(f"{domain}\n")
    
    print(f"   ‚úÖ Fichier cr√©√©: {filepath}")


async def save_progress(domains: Set[str], filepath: str):
    """
    Sauvegarde la progression pendant la r√©cup√©ration (fichier temporaire)
    
    Args:
        domains: Set de domaines actuels
        filepath: Chemin du fichier de sortie
    """
    progress_file = filepath + ".progress"
    
    async with aiofiles.open(progress_file, 'w') as f:
        await f.write(f"# R√©cup√©ration en cours...\n")
        await f.write(f"# Domaines trouv√©s jusqu'√† pr√©sent: {len(domains)}\n")
        await f.write(f"# Derni√®re mise √† jour: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")


async def main():
    """Point d'entr√©e principal"""
    print("=" * 80)
    print("üåê R√©cup√©ration des domaines .ch depuis crt.sh")
    print("=" * 80)
    print(f"\nüìÖ Ann√©es interrog√©es: {min(YEARS)} √† {max(YEARS)}")
    print(f"üìÅ Fichier de sortie: {OUTPUT_PATH}")
    print()
    
    # Callback pour sauvegarder la progression
    async def progress_callback(count):
        await save_progress(set(), OUTPUT_PATH)  # Sauvegarde juste le compteur
        print(f"   üìä Progression: {count} domaines trouv√©s jusqu'√† pr√©sent...")
    
    # R√©cup√©rer les domaines
    domains = await fetch_all_domains(verify_dns=False, progress_callback=progress_callback)  # DNS verification d√©sactiv√©e (trop lent)
    
    if not domains:
        print("\n‚ùå Aucun domaine trouv√©!")
        return 1
    
    # Sauvegarder
    await save_domains(domains, OUTPUT_PATH)
    
    print("\n" + "=" * 80)
    print("‚úÖ SUCC√àS")
    print("=" * 80)
    print(f"\nüìä Statistiques:")
    print(f"   - Domaines trouv√©s: {len(domains)}")
    print(f"   - Fichier: {OUTPUT_PATH}")
    print()
    print("üöÄ Prochaine √©tape:")
    print(f"   python -m backend.scan_ch_sites --domains-file {OUTFILE} --limit 500")
    print()
    
    return 0


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    exit(exit_code)
